{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPINiz4uXLE10wUq6k7CHP4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWqzYdljAUau","executionInfo":{"status":"ok","timestamp":1720250506916,"user_tz":-330,"elapsed":1610,"user":{"displayName":"ALB TECH","userId":"08687266280947726302"}},"outputId":"4905e019-7f35-4ec4-f9b1-0b1bec0a3456"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Loss: 0.3246585814644244\n","Epoch: 1000, Loss: 0.24765944034230525\n","Epoch: 2000, Loss: 0.23021244371361638\n","Epoch: 3000, Loss: 0.18293148459817582\n","Epoch: 4000, Loss: 0.14122099803410448\n","Epoch: 5000, Loss: 0.0838606806521025\n","Epoch: 6000, Loss: 0.040533395810759265\n","Epoch: 7000, Loss: 0.021937468018034728\n","Epoch: 8000, Loss: 0.013784955788478348\n","Epoch: 9000, Loss: 0.00962886601011026\n","Input: [0 0], Output: [0.10143897]\n","Input: [0 1], Output: [0.92569842]\n","Input: [1 0], Output: [0.92562684]\n","Input: [1 1], Output: [0.08694056]\n"]}],"source":["import numpy as np\n","\n","def sigmoid(x):\n","  return 1/(1+np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","  return x * (1 - x)\n","\n","def mean_squared_error_loss(y_true, y_pred):\n","  return np.mean(np.power(y_true - y_pred, 2))\n","\n","## input\n","input_data = np.array([[0,0], [0,1], [1,0], [1,1]])\n","output_data = np.array([[0], [1], [1], [0]])\n","\n","## Traning Parameter\n","np.random.seed(42)\n","input_size = 2\n","hidden_size = 2\n","output_size = 1\n","\n","## Random Weights & Bias\n","weights_input_to_hidden = np.random.rand(input_size, hidden_size)\n","bias_hidden = np.random.rand(hidden_size)\n","\n","weights_hidden_to_output = np.random.rand(hidden_size, output_size)\n","bias_output = np.random.rand(output_size)\n","\n","#Training Parameter\n","learning_rate = 0.1\n","epochs = 10000\n","\n","\n","for epoch in range(epochs):\n","  #forward pass\n","  hidden_input = np.dot(input_data, weights_input_to_hidden)+bias_hidden\n","  hidden_output = sigmoid(hidden_input)\n","\n","  final_input = np.dot(hidden_output, weights_hidden_to_output)+bias_output\n","  final_output = sigmoid(final_input)\n","\n","\n","  #computing loss\n","  loss = mean_squared_error_loss(output_data, final_output)\n","\n","  #backpropagation\n","  error = final_output-output_data\n","  gradient_output = error*sigmoid_derivative(final_output)\n","\n","  # hidden layer eror and gradient\n","  error_hidden = gradient_output.dot(weights_hidden_to_output.T)\n","  gradient_hidden = error_hidden*sigmoid_derivative(hidden_output)\n","\n","  #updatingweight and biases\n","  weights_hidden_to_output-=learning_rate*np.dot(hidden_output.T, gradient_output)\n","  bias_output-=learning_rate*np.mean(gradient_output, axis=0)\n","\n","  weights_input_to_hidden-=learning_rate*np.dot(input_data.T, gradient_hidden)\n","  bias_hidden-=learning_rate*np.mean(gradient_hidden, axis=0)\n","\n","  #print 1000 loss\n","  if epoch%1000==0:\n","    print(f'Epoch: {epoch}, Loss: {loss}')\n","\n","#compute out for each input pair after training\n","result = []\n","for input_pair in input_data:\n","  hidden_input = np.dot(input_pair, weights_input_to_hidden)+bias_hidden\n","  hidden_output = sigmoid(hidden_input)\n","  final_input = np.dot(hidden_output, weights_hidden_to_output)+bias_output\n","  final_output = sigmoid(final_input)\n","  result.append(final_output)\n","  print(f'Input: {input_pair}, Output: {final_output}')"]},{"cell_type":"code","source":[],"metadata":{"id":"Uq-6_Cmk9MBN"},"execution_count":null,"outputs":[]}]}